{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced95af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "  \n",
    "raw_data = pd.read_csv('data/targetfirm_prediction_dataset_small.csv')\n",
    "raw_data = raw_data.fillna(0)\n",
    "data = np.array(raw_data.values)\n",
    "data = data[:,1:]\n",
    "\n",
    "# print(data)\n",
    "\n",
    "# # GVKEY Labels\n",
    "labels = data[:,0]\n",
    "print(labels)\n",
    "# print(np.unique(labels, return_index=True, return_counts=True, axis=0))\n",
    "_,ind1,inv1,cou1 = np.unique(labels, return_index=True, return_inverse=True, return_counts=True)\n",
    "print(ind1)\n",
    "print(inv1)\n",
    "print(cou1)\n",
    "# Index of the last occurrence of the GVKEY\n",
    "print((ind1+cou1-1))\n",
    "target_indices = ind1+cou1-1\n",
    "print(\"Length of labels is \", len(target_indices))\n",
    "\n",
    "\n",
    "data_tensor = torch.FloatTensor(data)\n",
    "# print(data_tensor)\n",
    "\n",
    "print(\"*\"*100)\n",
    "def prepare_data_and_split(source_data, window_size, target_indices):\n",
    "    returndata = [ ]\n",
    "    print(len(source_data))\n",
    "    print(len(source_data[0]))\n",
    "    print(source_data[0])\n",
    "    print(\"*\"*100)\n",
    "    x_data = []\n",
    "    y_data = []\n",
    "    #     print(window_size)\n",
    "#     print(len(target_indices))\n",
    "    for i in target_indices:\n",
    "#         print(\"Processing --\", i)\n",
    "        current_index = i\n",
    "        previous_index = current_index - 1\n",
    "        count = 0 \n",
    "#         print(\"Year \", source_data[:,1][current_index], \" and year \", source_data[:,1][previous_index])\n",
    "        while(source_data[:,1][current_index] > source_data[:,1][previous_index] and count < window_size):\n",
    "            current_index-=1\n",
    "            previous_index = current_index - 1\n",
    "            count+=1\n",
    "#         print(current_index, i)\n",
    "        if(current_index == i):\n",
    "#             print(\"Skipping this\")\n",
    "            continue\n",
    "#         else:\n",
    "#             print(\"Processing for \", count, \" years--------------\")\n",
    "#         print(\"Processing for years start to end is \", source_data[:,1][current_index], source_data[:,1][i])\n",
    "#         print(\"Which is \", source_data[current_index:i,3:17])\n",
    "#         print(\"Target is \", source_data[i, 2])\n",
    "        x_data.append(source_data[current_index:i,3:17])\n",
    "        y_data.append(source_data[i,2])\n",
    "        returndata.append((source_data[current_index:i,3:17], source_data[i,2]))\n",
    "    print(\"Total returndata length is \", len(returndata))\n",
    "    print(len(returndata[0]))\n",
    "    test_size = int(np.round(0.3 * len(returndata)))\n",
    "    print(\"Test size is \", test_size)\n",
    "    train = returndata[:-test_size]\n",
    "    x_train = x_data[:-test_size]\n",
    "    y_train = y_data[:-test_size]\n",
    "    test = returndata[-test_size:]\n",
    "    x_test = x_data[-test_size:]\n",
    "    y_test = y_data[-test_size:]\n",
    "    return train, test, x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "print(\"*\"*100)\n",
    "year_window = 5 # Years\n",
    "train, test, x_train, y_train, x_test, y_test = prepare_data_and_split(data_tensor,year_window,target_indices)\n",
    "print(\"*\"*100)\n",
    "\n",
    "# print(train)\n",
    "print(len(train))\n",
    "print(len(test))\n",
    "print(len(x_train))\n",
    "print(len(y_train))\n",
    "print(len(x_train[0]))\n",
    "print(len(y_train))\n",
    "print(len(x_test))\n",
    "print(len(y_test))\n",
    "# test.head()\n",
    "\n",
    "\n",
    "input_size = 14\n",
    "hidden_size = 100 \n",
    "num_layers = 2 \n",
    "output_size = 1 \n",
    "num_epochs = 10 \n",
    "learning_rate = 0.05 \n",
    "\n",
    "# x_train = torch.from_numpy(np.asarray(x_train)).type(torch.Tensor)\n",
    "# x_test = torch.from_numpy(np.asarray(x_test)).type(torch.Tensor)\n",
    "# y_train = torch.from_numpy(np.asarray(y_train, dtype=np.float32)).type(torch.Tensor)\n",
    "# y_test = torch.from_numpy(np.asarray(y_test, dtype=np.float32)).type(torch.Tensor)\n",
    "\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size \n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "    \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.h_cell = (torch.zeros(self.num_layers,1, self.hidden_size),\n",
    "                       torch.zeros(self.num_layers,1, self.hidden_size))\n",
    "        \n",
    "    def forward(self,x): \n",
    "        out, self.h_cell = self.lstm(x.view(len(x),1,-1),self.h_cell)\n",
    "        output = self.fc(out.view(len(x),-1))\n",
    "        return output[-1]\n",
    "       \n",
    "# class GRU(nn.Module):\n",
    "#     def __init__(self, input_size, hidden_size ,num_layers, output_size):\n",
    "#         super(GRU, self).__init__()\n",
    "#         self.hidden_size = hidden_size \n",
    "#         self.input_size = input_size\n",
    "#         self.num_layers = num_layers\n",
    "        \n",
    "#         self.gru = nn.GRU(input_size, hidden_size, num_layers)\n",
    "#         self.fc = nn.Linear(hidden_size, output_size) \n",
    "#         self.h_cell = torch.zeros(self.num_layers,1, self.hidden_size)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         out, self.h_cell = self.gru(x.view(len(x),1,-1),self.h_cell)\n",
    "#         output = self.fc(out.view(len(x),-1))\n",
    "#         return output[-1]\n",
    "    \n",
    "lstm_model = LSTM(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers, output_size = output_size)\n",
    "\n",
    "print(\"Training LSTM\" + f\" model with {num_epochs} epochs:\")\n",
    "\n",
    "import time\n",
    "\n",
    "hist = np.zeros(num_epochs)\n",
    "\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "criterion = nn.MSELoss(reduction='mean')\n",
    "optimizer = torch.optim.Adam(lstm_model.parameters(), learning_rate)\n",
    "for i in range(num_epochs):\n",
    "    for training_data, y_lstm_targets in train:\n",
    "\n",
    "        y_train_pred = lstm_model(training_data)\n",
    "        loss = criterion(y_train_pred, y_lstm_targets)\n",
    "        print(\"Epoch \", i, \"MSE: \", loss.item())\n",
    "        hist[i] = loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(\"Time taken for the training is \", training_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93312a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf76b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
